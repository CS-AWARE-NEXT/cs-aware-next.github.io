<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deepfakes on CS-AWARE-NEXT</title><link>https://cs-aware-next.github.io/tags/deepfakes/</link><description>Recent content in Deepfakes on CS-AWARE-NEXT</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Tue, 26 Aug 2025 12:00:00 +0200</lastBuildDate><atom:link href="https://cs-aware-next.github.io/tags/deepfakes/index.xml" rel="self" type="application/rss+xml"/><item><title>From Phishing to Deepfakes: The Evolution of Social Engineering</title><link>https://cs-aware-next.github.io/blog/2025/08/26/blog_phishing_to_deepfakes/</link><pubDate>Tue, 26 Aug 2025 12:00:00 +0200</pubDate><guid>https://cs-aware-next.github.io/blog/2025/08/26/blog_phishing_to_deepfakes/</guid><description>&lt;p>For years, phishing emails were a very popular and effective tool for cybercriminals. They contained messages pretending to be from the recipient’s bank or a familiar company, designed to steal the victim’s login details. While phishing is still common, social engineering has evolved far beyond those emails. Contemporary scammers are using more sophisticated techniques, blending psychology with technology to manipulate people into giving up information, money, or access.&lt;/p>
&lt;p>One of the biggest shifts is the rise of deepfakes, that is highly realistic fake videos, audio clips, or images generated by artificial intelligence. Cybercriminals now use AI-powered voice cloning to impersonate CEOs in phone calls, tricking employees into transferring funds. Others create fake video messages that look like they came from trusted colleagues or even family members. These scams prey on trust, making it harder for people to tell what’s real and what’s fake.&lt;/p></description></item></channel></rss>