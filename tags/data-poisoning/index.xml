<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data Poisoning on CS-AWARE-NEXT</title><link>https://cs-aware-next.github.io/tags/data-poisoning/</link><description>Recent content in Data Poisoning on CS-AWARE-NEXT</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 25 Jan 2023 12:00:00 +0200</lastBuildDate><atom:link href="https://cs-aware-next.github.io/tags/data-poisoning/index.xml" rel="self" type="application/rss+xml"/><item><title>Data poisoning attacks</title><link>https://cs-aware-next.github.io/blog/2023/01/25/cs_aware_next_data_poisoning/</link><pubDate>Wed, 25 Jan 2023 12:00:00 +0200</pubDate><guid>https://cs-aware-next.github.io/blog/2023/01/25/cs_aware_next_data_poisoning/</guid><description>&lt;p&gt;Data poisoning is an increasingly important security concern for Machine Learning (ML) systems. As machine learning models are becoming more prevalent in our lives, they are also becoming more vulnerable to malicious attacks. Data poisoning attacks are one of the most insidious and difficult-to-detect kinds of threats on ML models.&lt;/p&gt;
&lt;p&gt;Data poisoning is a type of adversarial attack in which a cybercriminal injects malicious data into a machine learning model. These attacks can be used to manipulate the results of a machine learning system, or to redirect the system&amp;rsquo;s resources away from its intended purpose.&lt;/p&gt;</description></item></channel></rss>